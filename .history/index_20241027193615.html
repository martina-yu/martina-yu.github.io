<!doctype html>
<html>

<head>
  <title>Zi-Meng (Martina) Yu</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-103598896-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <!-- Header Section -->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <img class="image" id="me" src="./img/zimengyu_2.jpg" alt="Photo of Zi-Meng Yu">
          </div>
          <div class="flex-item flex-column">
            <h2>Zi-Meng (Martina) Yu</h2>
            <p class="text">
              Bachelor's Degree in Medicine<br>
              <a href="mailto:mengmeng2620@outlook.com">
                <i class="fas fa-envelope"></i> mengmeng2620@outlook.com</a><br>
              <a href="https://scholar.google.com/citations?user=ASUhwHAAAAAJ&hl=zh-TWn" target="_blank">
                <i class="fas fa-graduation-cap"></i> Google Scholar,
              </a>
              <a href="https://orcid.org/0009-0000-4467-198X" target="_blank">
                <i class="fab fa-orcid"></i> ORCiD
              </a><br>
              <a href="https://en.sjtu.edu.cn" target="_blank">
                <i class="fas fa-school"></i> Shanghai Jiao Tong University
              </a><br>
              <a href="https://medicine.yale.edu" target="_blank">
                <i class="fas fa-school"></i> Yale University</a><br>
            </p>
          </div>
        </div>
        <!-- Research Interests Section -->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 id="researchinterests">Research Interests</h2>
            <hr>
            <!-- <p class="text">
              Computational Biology, Bioinformatics, Quantitative Biology, Deep Learning<br>
              Genetics, Genomics, Molecular Biology, Synthetic Biology<br>
              CRISPR/Cas9, Gene Seqeuncing, Protein Design, Drug Discovery, Cell-Cell & Protein interactions<br> -->
              <div class="category general-discipline">
                <strong>General Discipline:</strong><br>
                Computational Biology, Bioinformatics, Quantitative Biology, Deep Learning, , Computer Vision, Natural Language Processing
              </div>
              
              <div class="category bio-field">
                <strong>Biological Field:</strong><br>
                Genetics, Genomics, Molecular Biology, Synthetic Biology
              </div>
              
              <div class="category detailed-interests">
                <strong>Detailed Interests:</strong><br>
                CRISPR/Cas9, Gene Sequencing, Protein Design, Drug Discovery, Cell-Cell & Protein Interactions
              </div>
            </p>
          </div>
        </div>
        <!-- Table of Contents -->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h3>Table of Contents</h3>
            <ul>
              <li><a href="#biography">Biography</a></li>
              <li><a href="#experience">Experience</a></li>
              <li><a href="#publications">Publications</a></li>
              <li><a href="#projects">Projects</a></li>
              <li><a href="#awards">Awards and Honors</a></li>
            </ul>
          </div>
        </div>
        <!-- Biography Section -->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 id="biography">Biography</h2>
            <hr>
            <p class="text">
              I'm a senior undergraduate student at <strong>Shanghai Jiao Tong University (SJTU)</strong>, during my majoring in Preventive Medicine with a minor in Health Management, I was keeping self-teaching and selecting basic computer science including programming languages, data structures, and algorithms such as machine learning. I have got great grades of all these courses and yet my schedules were filled with medical courses, which can be seen on my CV.
              
              From Fall 2020 to Spring 2025, I've undertaken over 90 courses, amassing more than 250 credits. I'm proud to <strong>have been the 1st student twice</strong> in my class and achieved a <strong>GPA of 3.91/4.0</strong> from Spring 2022 to Fall 2024, scoring above 89 in 43 courses—even though our university only awards the top 30% of students with scores over 85.
            </p>
            <p class="text">
              My academic interests span computational biology, deep learning, genetics, and medicine. My passion for computational programming ignited in 2021 when I began working on a CRISPR/Cas9 project under the mentorship of <a href="https://scholar.google.com/citations?hl=en&user=7d3TckgAAAAJ">Prof. CD. Zhang</a> and <a href="https://orcid.org/0000-0002-2981-4150">Prof. Leming Shi</a> (Wroked in FDA, educated in Princeton) and <a href="https://pubmed.ncbi.nlm.nih.gov/?sort=date&term=Wang+Y&cauthor_id=25082577">Prof. Yongming Wang</a>. Since then, I've participated and constructed in various projects involving deep learning models such as <strong>GNN, LSTM, GAT, MML</strong>, and have also gained experience in website design. The code of my projects <strong>used <a href="https://github.com/martina-yu/bedeepon">LSTM wrote by me</a> and <a href="https://github.com/martina-yu/Cell-Cell-Communication">GNN & GAT</a> is available on Github, which is the best evidence of my programming skills</strong>.
            </p>
            <p class="text">
              I love linguistics, especially I have a deep appreciation for Japanese culture—speaking some Japanese and enjoying Japanese songs. 
            </p>
            
            <p class="text"><
              Additionally, I've been self-teaching drawing for over 10 years, creating more than 100 pieces of artwork for university and personal projects. This creative pursuit has not only enriched my life but also helped fund my travels and hobbies.

              The designed gift box for Mid-Autumn Festival is shown as following:
            </p>

            <div style="text-align: center;">
              <img class="image" id="midautumn" src="./img/midautumn.png" alt="midautumn" style="width:50%;" />
            </div>
            
          </div>
        </div>
        <!-- Experience Section -->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 id="experience">Experience</h2>
            <hr>
            <!-- First Research Experience -->
            <h3>First Research Experience</h3>
            <p class="text">
              In early 2022, I was thrilled to join <a href="https://scholar.google.com/citations?hl=en&user=7d3TckgAAAAJ">Prof. CD. Zhang's</a> lab, co-guided by and <a href="https://orcid.org/0000-0002-2981-4150">Prof. Leming Shi</a> and <a href="https://pubmed.ncbi.nlm.nih.gov/?sort=date&term=Wang+Y&cauthor_id=25082577">Prof. Yongming Wang</a>. One of the first papers I delved into was "<a href="https://www.nature.com/articles/s41587-020-00793-4">Deep learning design of adeno-associated virus capsids for gene therapy</a>." This paper introduced me to the exciting intersection of deep learning and biomedical research, laying the groundwork for my future projects.
            </p>
            <!-- Multimodal Deep Learning Study -->
            <h3>Exploring Multimodal Deep Learning in Medicine</h3>
            <p class="text">
              In September 2022, I engaged with the study "<a href="https://doi.org/10.1016/j.ccell.2022.07.004">Pan-cancer integrative histology-genomic analysis with deep learning</a>." Working with the TCGA database, I learned to process raw data and reproduce advanced methods like <a href="https://github.com/mahmoodlab/PORPOISE">PORPOISE</a> and <a href="https://github.com/mahmoodlab/CLAM">CLAM</a>. This experience was pivotal in enhancing my understanding of applying deep learning techniques to cancer data analysis.
            </p>
            <!-- AI Drug Competition -->
            <h3>Participation in the First AI Drug Competition by Baidu</h3>
            <p class="text">
              In May 2023, I participated in the <a href="https://aistudio.baidu.com/competition/detail/1012/0/task-definition">First Global AI Drug Development Competition</a> organized by Baidu. The competition centered on predicting the inhibitory activity of small molecules against the main protease of SARS-CoV-2 using deep learning and docking methods. As part of the team, I contributed by updating outcomes and reproducing results in JupyterLab. Although we didn't secure an award, the competition significantly honed my Python programming skills and deepened my understanding of AI applications in drug development.
            </p>
            <!-- Personal Growth -->
            <h3>Personal Growth and Character</h3>
            <p class="text">
              Throughout my academic journey, I've been driven by a genuine passion for learning rather than external accolades. I may not have always been at the top of my class initially, but my dedication and love for exploration have consistently propelled me forward. This intrinsic motivation has often led me to exceed expectations and achieve success in areas I'm truly passionate about.
            </p>
          </div>
        </div>
        <!-- Publications Section -->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 id="publications">Publications</h2>
            <hr>
            <h3>A Predictive radiotherapy response for HNSCC: based on a ceRNA network</h3>
          
              <img class="image" id="HNSCC" src="./img/HNSCC.png" alt="HNSCC"/>

            <p class="text">
              The thesis is under reviewing and anticipated to be submitted at the end of this year (Nov).

              Head and neck squamous cell carcinoma (HNSCC), as the seventh most prevalent cancer worldwide, is a malignant neoplasm arising from the epithelial lining of the mucosal surfaces in the head and neck region, including the oral cavity, pharynx, and larynx. Radiotherapy(RT) is one of the cornerstones of treatment modality in HNSCC and offering approximately 75% patients potential benefits during their course of illness. Nonetheless, it comes with inevitable radiation does to normal tissues, thus, achieving the most prolific and specific treatment outcome for individuals requires a quantitative description of their contribution to tumor control and side-effects with the help of models. Expressly, putting a close eye on comprehensively considering its various disease-, patient- and treatment-related factors is particularly important for clinical practice to formulate an appropriate radiotherapy scheme.
            </p>
            <h3>ML tool of on-target Base Editor</h3>
            <p class="text">
              The preprinting is published <a href="https://www.biorxiv.org/content/10.1101/2021.03.14.435303v2.abstract">here</a>. And the code wrote by me can be seen now in <a href="https://github.com/martina-yu/bedeepon">github</a>.

              Base editors enable direct conversion of one target base into another in a programmable manner, but conversion efficiencies vary dramatically among different targets. Here, we performed a high-throughput gRNA-target library screening to measure conversion efficiencies and outcome product frequencies at integrated genomic targets and obtained datasets of 60,615 and 73,303 targets for ABE and CBE, respectively. We used the datasets to train deep learning models, resulting in ABEdeepon and CBEdeepon which can predict on-target efficiencies and outcome sequence frequencies. The software is freely accessible via online web server <a href="http://www.deephf.com/#/bedeep/bedeepon">bedeepon tool website</a>.

              <div style="text-align:center;">
                <img class="image" id="Crispr" src="./img/bedeepon.png" alt="bedeepon">
              </div>
            </p>
          </div>
        </div>
        <!-- Projects Section -->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 id="projects">Projects</h2>
            <hr>
            <h3>Cell to Cell communication</h3>
            <p class="text">
              Dysregulation of communication between cells mediates complex diseases such as cancer and diabetes. However, detecting cell-cell communication (CCC) at scale remains one of the greatest challenges in transcriptomics. While gene expression measured with single-cell RNA sequencing and spatial transcriptomics reinvigorated computational approaches to detecting CCC, most existing methods exhibit high false positive rates, do not integrate spatial proximity of ligand-receptor interactions, and cannot detect CCC between individual cells.
            </p>
            <p class="text">
              In this project, we will develop a novel model with graph attention networks(GAT) to solve this problem. However, the critical problem is the missing of "ground-truth" of communication. Thus, we conduct a new method to solidify our preprocessing pipeline combined with both ligand-receptor interactions and downstream gene expression data. Besides, it comes up with a new benchmarking way to evaluate the performance of our model, rather than relying on traditional ways such as MSE score considering its biological meaning.
            </p>
              <img class="image" id="STARmap" src="./img/starmap.jpg" alt="STARmap">
              <img class="image" id="cellcellcommunication" src="./img/cellcellcommunication.png" alt="cellcellcommunication"/>
            </p>
            <h3>Multimodel deep learning in response to radiology thesis</h3>
            <p class="text">

              As the chatbot raising, it brings up a cutting-edge and sophisticated method for handling reports and researches of radiology and radiotherapy. Inspired by ChatGPT, we are developing a multimodel deep learning model to respond to extract and summarize radiology reports including annotating and analyzing images. Notably, our model was trained on a large raiological database collected by ourselves which contains over 2,000 radiology reports and over 100,000 images. The invoked model catch the tremendous potential of assisting researchers, radiologists and doctors in their daily work, providing a welfare to society.

              <img class="image" id="ChatbotRadiology" src="./img/chatbot_radiology.png" alt="ChatbotRadiology">
            </p>
            <!-- You can add detailed project descriptions here -->
          </div>
        </div>
        <!-- Awards and Honors Section -->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 id="awards">Awards and Honors</h2>
            <hr>
            <ul>
              <li>A(First Class) Scholarship (Top 1), Shanghai Jiao Tong University, 2023, 200$</li>
              <li>B(Second Class) Scholarship (Top 5), Shanghai Jiao Tong University, 2024, 150$</li>
              <li>Overseas Research Training Support Program Scholarship, 2024, 2800$</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</body>

</html>
